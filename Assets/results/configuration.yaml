default_settings:
  trainer_type: ppo
  hyperparameters:
    batch_size: 1024
    buffer_size: 10240
    learning_rate: 0.3
    learning_rate_schedule: linear
  network_settings:
    normalize: false
    hidden_units: 128
    num_layers: 2
    vis_encode_type: simple

    #memory
    use_recurrent: true
    sequence_length: 64
    memory_size: 256

  reward_signals:
    curiosity:
      gamma: 0.99
      strength: 0.02
    extrinsic:
      gamma: 0.99
      strength: 1.0
  init_path: null
  keep_checkpoints: 5
  checkpoint_interval: 500000
  max_steps: 50000000
  time_horizon: 64
  summary_freq: 50000
  threaded: true
  self_play:
    window: 10
    save_steps: 10000
    swap_steps: 10000
    play_against_latest_model_ratio: 0.5
  behavioral_cloning: null
  framework: tensorflow
behaviors: {}
env_settings:
  env_path: null
  env_args: null
  base_port: 5005
  num_envs: 1
  seed: -1
engine_settings:
  width: 84
  height: 84
  quality_level: 5
  time_scale: 1
  target_frame_rate: -1
  capture_frame_rate: 60
  no_graphics: false
environment_parameters: null
checkpoint_settings:
  run_id: 9
  initialize_from: null
  load_model: false
  resume: false
  force: false
  train_model: true
  inference: false
debug: false
